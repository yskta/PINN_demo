{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xとtのスケーリング\n",
    "import sys\n",
    "sys.path.insert(0, './Utilities/')\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "K = 0.47\n",
    "rho = 1573\n",
    "cp = 967\n",
    "alpha = K / (rho * cp)\n",
    "\n",
    "h1 = 100\n",
    "h2 = 50\n",
    "\n",
    "lambda_u, lambda_f, lambda_BC0, lambda_BC1, lambda_BC2 = 1.0, 1.0, 1.0, 1.0, 1.0 \n",
    "\n",
    "N_u = 500\n",
    "N_f = 10000\n",
    "layers = [2, 50, 50, 50, 50, 50, 50, 50, 50, 1]\n",
    "\n",
    "x = np.linspace(0, 0.2, 100)[:, None]\n",
    "t = np.linspace(0, 3600, 3600)[:, None]\n",
    "dx = x[1] - x[0]\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "Nx = len(x)\n",
    "Nt = len(t)\n",
    "u = np.zeros((Nt, Nx))\n",
    "\n",
    "for n in range(0, Nt - 1):\n",
    "    if t[n] <= 600:\n",
    "        T_ext1 = T_ext2 = 0 + (50 - 0) * t[n] / 600\n",
    "    else:\n",
    "        T_ext1 = T_ext2 = 50\n",
    "    for i in range(1, Nx - 1):\n",
    "        u[n + 1, i] = u[n, i] + alpha * dt * (u[n, i - 1] - 2 * u[n, i] + u[n, i + 1]) / dx**2\n",
    "\n",
    "    u[n + 1, 0] = (4 * u[n + 1, 1] - u[n + 1, 2] + 2 * dx * h1 / K * T_ext1) / (3 + 2 * dx * h1 / K)\n",
    "    u[n + 1, -1] = (4 * u[n + 1, -2] - u[n + 1, -3] + 2 * dx * h2 / K * T_ext2) / (3 + 2 * dx * h2 / K)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img1 = ax1.imshow(u.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img1, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Exact Temperature Distribution', fontsize=15)\n",
    "ax1.set_xlabel('Time [s]', fontsize=12)\n",
    "ax1.set_ylabel('Position [m]', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = u.flatten()[:, None]\n",
    "\n",
    "# ドメインの境界\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "# 初期条件と境界条件のデータを準備\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = u[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = u[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = u[:, -1:]\n",
    "\n",
    "# 初期・境界条件のデータを結合\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "# ランダムサンプリング\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]\n",
    "\n",
    "def scale_x(x):\n",
    "    return 2.0 * (x - lb[0]) / (ub[0] - lb[0]) - 1.0\n",
    "\n",
    "def scale_t(t):\n",
    "    return (t - lb[1]) / (ub[1] - lb[1])\n",
    "\n",
    "def unscale_x(x):\n",
    "    return 0.5 * (x + 1.0) * (ub[0] - lb[0]) + lb[0]\n",
    "\n",
    "def unscale_t(t):\n",
    "    return t * (ub[1] - lb[1]) + lb[1]\n",
    "\n",
    "X_u_train_scaled = np.copy(X_u_train)\n",
    "X_u_train_scaled[:, 0] = scale_x(X_u_train[:, 0])\n",
    "X_u_train_scaled[:, 1] = scale_t(X_u_train[:, 1])\n",
    "\n",
    "X_f_train_scaled = np.copy(X_f_train)\n",
    "X_f_train_scaled[:, 0] = scale_x(X_f_train[:, 0])\n",
    "X_f_train_scaled[:, 1] = scale_t(X_f_train[:, 1])\n",
    "\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = torch.nn.ELU\n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(('layer_%d' % i, torch.nn.Linear(layers[i], layers[i + 1])))\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "        layer_list.append(('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1])))\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, rho, cp, alpha, k, h1, h2, T0):\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        self.x_u = torch.tensor(X_u[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_u = torch.tensor(X_u[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        self.layers = layers\n",
    "        self.k = k\n",
    "        self.rho = rho\n",
    "        self.alpha = alpha\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.T0 = T0\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters(), lr=1e-4)\n",
    "        self.lambda_f = torch.tensor(lambda_f, requires_grad=True, device=device)\n",
    "        self.lambda_BC0 = torch.tensor(lambda_BC0, requires_grad=True, device=device)\n",
    "        self.lambda_BC1 = torch.tensor(lambda_BC1, requires_grad=True, device=device)\n",
    "        self.lambda_BC2 = torch.tensor(lambda_BC2, requires_grad=True, device=device)\n",
    "\n",
    "    def net_t_inf(self, t):\n",
    "        t_unscaled = unscale_t(t)\n",
    "        t_inf_unscaled = torch.where(t_unscaled <= 600, 50 * t_unscaled / 600, torch.tensor(50.0).to(device))\n",
    "        t_inf = scale_t(t_inf_unscaled)\n",
    "        return t_inf\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        u = self.dnn(torch.cat([x, t], dim=1))\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        f = self.alpha * u_xx - u_t\n",
    "        return f\n",
    "\n",
    "    def net_BC0(self, x):\n",
    "        t = torch.zeros_like(x)\n",
    "        u = self.net_u(x, t)\n",
    "        BC0 = self.T0 - u\n",
    "        return BC0\n",
    "\n",
    "    def net_BC1(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC1 = - (t_inf - u) + (self.k / self.h1) * u_x\n",
    "        return BC1\n",
    "\n",
    "    def net_BC2(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC2 = t_inf - u - (self.k / self.h2) * u_x\n",
    "        return BC2\n",
    "\n",
    "    def loss_func(self):\n",
    "        f_pred = self.net_f(self.x_f, self.t_f)\n",
    "        x_BC0 = self.x_f[self.t_f == 0]\n",
    "        BC0_pred = self.net_BC0(x_BC0)\n",
    "        x_BC1 = torch.full((self.t_f.shape[0], 1), 1.0, requires_grad=True).to(device)\n",
    "        t_BC1 = self.t_f\n",
    "        BC1_pred = self.net_BC1(x_BC1, t_BC1)\n",
    "        x_BC2 = torch.full((self.t_f.shape[0], 1), -1.0, requires_grad=True).to(device)\n",
    "        t_BC2 = self.t_f\n",
    "        BC2_pred = self.net_BC2(x_BC2, t_BC2)\n",
    "        loss_f = torch.mean(f_pred**2)\n",
    "        loss_BC0 = torch.mean(BC0_pred**2)\n",
    "        loss_BC1 = torch.mean(BC1_pred**2)\n",
    "        loss_BC2 = torch.mean(BC2_pred**2)\n",
    "        total_loss = self.lambda_f * loss_f + self.lambda_BC0 * loss_BC0 + self.lambda_BC1 * loss_BC1 + self.lambda_BC2 * loss_BC2\n",
    "        return total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2\n",
    "\n",
    "    def train(self, nIter):\n",
    "        for epoch in range(nIter):\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2 = self.loss_func()\n",
    "            total_loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            with torch.no_grad():\n",
    "                self.lambda_f *= torch.exp(0.1 * loss_f.detach() / total_loss.detach())\n",
    "                self.lambda_BC0 *= torch.exp(0.1 * loss_BC0.detach() / total_loss.detach())\n",
    "                self.lambda_BC1 *= torch.exp(0.1 * loss_BC1.detach() / total_loss.detach())\n",
    "                self.lambda_BC2 *= torch.exp(0.1 * loss_BC2.detach() / total_loss.detach())\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}: Total Loss: {total_loss.item():.4e}, Loss f: {loss_f.item():.4e}, Loss BC0: {loss_BC0.item():.4e}, Loss BC1: {loss_BC1.item():.4e}, Loss BC2: {loss_BC2.item():.4e}')\n",
    "                print(f'lambda_f: {self.lambda_f.item()}, lambda_BC0: {self.lambda_BC0.item()}, lambda_BC1: {self.lambda_BC1.item()}, lambda_BC2: {self.lambda_BC2.item()}')\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        x_star = torch.tensor(X_star[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t_star = torch.tensor(X_star[:, 1:2], requires_grad=True).float().to(device)\n",
    "        x_star_scaled = scale_x(x_star)\n",
    "        t_star_scaled = scale_t(t_star)\n",
    "        u_star = self.net_u(x_star_scaled, t_star_scaled)\n",
    "        f_star = self.net_f(x_star_scaled, t_star_scaled)\n",
    "        return u_star.detach().cpu().numpy(), f_star.detach().cpu().numpy()\n",
    "\n",
    "T0 = u_train[X_u_train[:,1] == 0].mean().item()\n",
    "\n",
    "# モデルのインスタンス化\n",
    "model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0)\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.train(5000)\n",
    "\n",
    "# 予測\n",
    "u_pred, f_pred = model.predict(X_star)\n",
    "\n",
    "# 誤差の計算\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "print('Error u: %e' % (error_u))                     \n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h_img2 = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "              extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar = fig.colorbar(h_img2, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "ax.plot(\n",
    "    X_u_train[:,1], \n",
    "    X_u_train[:,0], \n",
    "    'kx', label = 'Data (%d points)' % (u_train.shape[0]), \n",
    "    markersize = 4, \n",
    "    clip_on = False,\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# 誤差の計算\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "# 温度分布の可視化\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 予測温度分布\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img3 = ax1.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img3, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Predicted Temperature Distribution')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Position [m]')\n",
    "\n",
    "# 残差の可視化\n",
    "ax2 = fig.add_subplot(212)\n",
    "h_img4 = ax2.imshow(Error.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider2 = make_axes_locatable(ax2)\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar2 = fig.colorbar(h_img4, cax=cax2)\n",
    "cbar2.ax.tick_params(labelsize=15)\n",
    "ax2.set_title('Absolute Error Distribution')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "ax2.set_ylabel('Position [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xとtのスケーリング\n",
    "#uのスケーリング\n",
    "#ver1\n",
    "#希望ある。\n",
    "import sys\n",
    "sys.path.insert(0, './Utilities/')\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "K = 0.47\n",
    "rho = 1573\n",
    "cp = 967\n",
    "alpha = K / (rho * cp)\n",
    "\n",
    "h1 = 100\n",
    "h2 = 50\n",
    "\n",
    "lambda_u, lambda_f, lambda_BC0, lambda_BC1, lambda_BC2 = 1.0, 1.0, 1.0, 1.0, 1.0 \n",
    "\n",
    "N_u = 500\n",
    "N_f = 10000\n",
    "layers = [2, 50, 50, 50, 50, 50, 50, 50, 50, 1]\n",
    "\n",
    "x = np.linspace(0, 0.2, 100)[:, None]\n",
    "t = np.linspace(0, 3600, 3600)[:, None]\n",
    "dx = x[1] - x[0]\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "Nx = len(x)\n",
    "Nt = len(t)\n",
    "u = np.zeros((Nt, Nx))\n",
    "\n",
    "for n in range(0, Nt - 1):\n",
    "    if t[n] <= 600:\n",
    "        T_ext1 = T_ext2 = 0 + (50 - 0) * t[n] / 600\n",
    "    else:\n",
    "        T_ext1 = T_ext2 = 50\n",
    "    for i in range(1, Nx - 1):\n",
    "        u[n + 1, i] = u[n, i] + alpha * dt * (u[n, i - 1] - 2 * u[n, i] + u[n, i + 1]) / dx**2\n",
    "\n",
    "    u[n + 1, 0] = (4 * u[n + 1, 1] - u[n + 1, 2] + 2 * dx * h1 / K * T_ext1) / (3 + 2 * dx * h1 / K)\n",
    "    u[n + 1, -1] = (4 * u[n + 1, -2] - u[n + 1, -3] + 2 * dx * h2 / K * T_ext2) / (3 + 2 * dx * h2 / K)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img1 = ax1.imshow(u.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img1, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Exact Temperature Distribution', fontsize=15)\n",
    "ax1.set_xlabel('Time [s]', fontsize=12)\n",
    "ax1.set_ylabel('Position [m]', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = u.flatten()[:, None]\n",
    "\n",
    "# ドメインの境界\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "# print(lb, ub)\n",
    "# [0. 0.] [2.0e-01 3.6e+03]\n",
    "\n",
    "# 初期条件と境界条件のデータを準備\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = u[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = u[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = u[:, -1:]\n",
    "\n",
    "# xx1は初期条件。uu1はt=0の時の温度分布\n",
    "# print('xx1:', xx1.shape)→(100, 2)\n",
    "# print('uu1:', uu1.shape)→(100, 1)\n",
    "# xx2はx=0の境界条件。uu2はx=0の境界条件の温度分布\n",
    "# print('xx2:', xx2.shape)→(3600, 2)\n",
    "# print('xx2[:, 0:1]:', xx2[:, 0:1])\n",
    "# print('uu2:', uu2.shape)\n",
    "# print('uu2[:, 0:1]:', uu2[:, 0:1])\n",
    "# xx3はx=0.2の境界条件。uu3はx=0.2の境界条件の温度分布\n",
    "# print('xx3:', xx3.shape)→(3600, 2)\n",
    "# print('xx3[:, -1:]:', xx3[:, -1:])\n",
    "# print('uu3:', uu3.shape)\n",
    "# print('uu3[:, -1:]:', uu3[:, -1:])\n",
    "\n",
    "# 初期・境界条件のデータを結合\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "# print('X_u_train:', X_u_train.shape)→(7300, 2)。3600+3600+100=7300\n",
    "\n",
    "# ランダムサンプリング\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "# print('X_f_train:', X_f_train.shape)→(10000, 2)\n",
    "# print('X_f_train:', X_f_train)\n",
    "\n",
    "#ランダムサンプリングのデータと初期・境界条件のデータを結合\n",
    "# もしかすると必要ないかも。X_u_trainのデータがあるので。\n",
    "# 上手くいくなら消す。いかないなら残す。 \n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "# print('X_f_train:', X_f_train.shape)→(17300, 2)\n",
    "# print('X_f_train.tail:', X_f_train[-1])\n",
    "\n",
    "# 初期・境界条件での温度分布\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "# print('u_train:', u_train.shape)→(500,1)\n",
    "\n",
    "# X_u_trainの行数からN_u個のランダムなインデックスを生成。\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "# 初期・境界条件のデータをN_u個に絞る\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]\n",
    "\n",
    "# まとめ\n",
    "# X_u_train: 初期・境界条件の位置・時間データ\n",
    "# u_train: 初期・境界条件の温度データ\n",
    "# X_f_train: ランダムサンプリングの位置・時間データ\n",
    "\n",
    "def scale_x(x):\n",
    "    return 2.0 * (x - lb[0]) / (ub[0] - lb[0]) - 1.0\n",
    "\n",
    "def scale_t(t):\n",
    "    return (t - lb[1]) / (ub[1] - lb[1])\n",
    "\n",
    "def scale_u(u):\n",
    "    return (u - u_min) / (u_max - u_min)\n",
    "\n",
    "def unscale_x(x):\n",
    "    return 0.5 * (x + 1.0) * (ub[0] - lb[0]) + lb[0]\n",
    "\n",
    "def unscale_t(t):\n",
    "    return t * (ub[1] - lb[1]) + lb[1]\n",
    "\n",
    "def unscale_u(u):\n",
    "    return u * (u_max - u_min) + u_min\n",
    "\n",
    "# 初期・境界条件・ランダムサンプリングのデータをスケーリング\n",
    "X_u_train_scaled = np.copy(X_u_train)\n",
    "X_u_train_scaled[:, 0] = scale_x(X_u_train[:, 0])\n",
    "X_u_train_scaled[:, 1] = scale_t(X_u_train[:, 1])\n",
    "\n",
    "X_f_train_scaled = np.copy(X_f_train)\n",
    "X_f_train_scaled[:, 0] = scale_x(X_f_train[:, 0])\n",
    "X_f_train_scaled[:, 1] = scale_t(X_f_train[:, 1])\n",
    "\n",
    "# print('X_u_train_scaled:', X_u_train_scaled[:10])\n",
    "# print('X_f_train_scaled:', X_f_train_scaled[:10])\n",
    "# print('X_u_train_scaleの位置の最小値:', X_u_train_scaled[:, 0].min()):-1\n",
    "# print('X_u_train_scaleの位置の最大値:', X_u_train_scaled[:, 0].max()):1\n",
    "# print('X_u_train_scaleの時間の最小値:', X_u_train_scaled[:, 1].min()):0\n",
    "# print('X_u_train_scaleの時間の最大値:', X_u_train_scaled[:, 1].max()):1\n",
    "# print('X_f_train_scaleの位置の最小値:', X_f_train_scaled[:, 0].min()):-1\n",
    "# print('X_f_train_scaleの位置の最大値:', X_f_train_scaled[:, 0].max()):1\n",
    "# print('X_f_train_scaleの時間の最小値:', X_f_train_scaled[:, 1].min()):0\n",
    "# print('X_f_train_scaleの時間の最大値:', X_f_train_scaled[:, 1].max()):1\n",
    "\n",
    "# 温度データのスケーリング\n",
    "u_min, u_max = u_train.min(), u_train.max()\n",
    "u_train_scaled = scale_u(u_train)\n",
    "# print('u_min', u_min):0\n",
    "# print('u_max', u_max):45.880\n",
    "# print('u_train_scaled:', u_train_scaled[:10])\n",
    "# print('u_train_scaledの最小値:', u_train_scaled.min()):0\n",
    "# print('u_train_scaledの最大値:', u_train_scaled.max()):1.0\n",
    "\n",
    "T0 = u_train[X_u_train[:,1] == 0].mean().item()\n",
    "T0_scaled = scale_u(T0)\n",
    "# print('T0:', T0):0.0\n",
    "\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = torch.nn.ELU\n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(('layer_%d' % i, torch.nn.Linear(layers[i], layers[i + 1])))\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "        layer_list.append(('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1])))\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, rho, cp, alpha, k, h1, h2, T0):\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        self.x_u = torch.tensor(X_u[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_u = torch.tensor(X_u[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        self.layers = layers\n",
    "        self.k = k\n",
    "        self.rho = rho\n",
    "        self.alpha = alpha\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.T0 = T0\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters(), lr=1e-4)\n",
    "        self.lambda_f = torch.tensor(lambda_f, requires_grad=True, device=device)\n",
    "        self.lambda_BC0 = torch.tensor(lambda_BC0, requires_grad=True, device=device)\n",
    "        self.lambda_BC1 = torch.tensor(lambda_BC1, requires_grad=True, device=device)\n",
    "        self.lambda_BC2 = torch.tensor(lambda_BC2, requires_grad=True, device=device)\n",
    "\n",
    "    def net_t_inf(self, t):\n",
    "        t_unscaled = unscale_t(t)\n",
    "        t_inf_unscaled = torch.where(t_unscaled <= 600, 50 * t_unscaled / 600, torch.tensor(50.0).to(device))\n",
    "        t_inf = scale_t(t_inf_unscaled)\n",
    "        return t_inf\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        u = self.dnn(torch.cat([x, t], dim=1))\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        f = self.alpha * u_xx - u_t\n",
    "        return f\n",
    "\n",
    "    def net_BC0(self, x):\n",
    "        t = torch.zeros_like(x)\n",
    "        u = self.net_u(x, t)\n",
    "        BC0 = self.T0 - u\n",
    "        return BC0\n",
    "\n",
    "    def net_BC1(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC1 = - (t_inf - u) + (self.k / self.h1) * u_x\n",
    "        return BC1\n",
    "\n",
    "    def net_BC2(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC2 = t_inf - u - (self.k / self.h2) * u_x\n",
    "        return BC2\n",
    "\n",
    "    def loss_func(self):\n",
    "        f_pred = self.net_f(self.x_f, self.t_f)\n",
    "        x_BC0 = self.x_f[self.t_f == 0]\n",
    "        BC0_pred = self.net_BC0(x_BC0)\n",
    "        x_BC1 = torch.full((self.t_f.shape[0], 1), 1.0, requires_grad=True).to(device)\n",
    "        t_BC1 = self.t_f\n",
    "        BC1_pred = self.net_BC1(x_BC1, t_BC1)\n",
    "        x_BC2 = torch.full((self.t_f.shape[0], 1), -1.0, requires_grad=True).to(device)\n",
    "        t_BC2 = self.t_f\n",
    "        BC2_pred = self.net_BC2(x_BC2, t_BC2)\n",
    "        loss_f = torch.mean(f_pred**2)\n",
    "        loss_BC0 = torch.mean(BC0_pred**2)\n",
    "        loss_BC1 = torch.mean(BC1_pred**2)\n",
    "        loss_BC2 = torch.mean(BC2_pred**2)\n",
    "        total_loss = self.lambda_f * loss_f + self.lambda_BC0 * loss_BC0 + self.lambda_BC1 * loss_BC1 + self.lambda_BC2 * loss_BC2\n",
    "        return total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2\n",
    "\n",
    "    def train(self, nIter):\n",
    "        for epoch in range(nIter):\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2 = self.loss_func()\n",
    "            total_loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            with torch.no_grad():\n",
    "                self.lambda_f *= torch.exp(0.1 * loss_f.detach() / total_loss.detach())\n",
    "                self.lambda_BC0 *= torch.exp(0.1 * loss_BC0.detach() / total_loss.detach())\n",
    "                self.lambda_BC1 *= torch.exp(0.1 * loss_BC1.detach() / total_loss.detach())\n",
    "                self.lambda_BC2 *= torch.exp(0.1 * loss_BC2.detach() / total_loss.detach())\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}: Total Loss: {total_loss.item():.4e}, Loss f: {loss_f.item():.4e}, Loss BC0: {loss_BC0.item():.4e}, Loss BC1: {loss_BC1.item():.4e}, Loss BC2: {loss_BC2.item():.4e}')\n",
    "                print(f'lambda_f: {self.lambda_f.item()}, lambda_BC0: {self.lambda_BC0.item()}, lambda_BC1: {self.lambda_BC1.item()}, lambda_BC2: {self.lambda_BC2.item()}')\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        x_star = torch.tensor(X_star[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t_star = torch.tensor(X_star[:, 1:2], requires_grad=True).float().to(device)\n",
    "        x_star_scaled = scale_x(x_star)\n",
    "        t_star_scaled = scale_t(t_star)\n",
    "        u_star_scaled = self.net_u(x_star_scaled, t_star_scaled)\n",
    "        u_star = unscale_u(u_star_scaled)\n",
    "        return u_star.detach().cpu().numpy()\n",
    "\n",
    "# モデルのインスタンス化\n",
    "# model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0)\n",
    "model = PhysicsInformedNN(X_u_train_scaled, u_train_scaled, X_f_train_scaled, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0_scaled)\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.train(1000)\n",
    "\n",
    "# 予測\n",
    "u_pred = model.predict(X_star)\n",
    "\n",
    "# 誤差の計算\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "print('Error u: %e' % (error_u))                     \n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h_img2 = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "              extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar = fig.colorbar(h_img2, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "ax.plot(\n",
    "    X_u_train[:,1], \n",
    "    X_u_train[:,0], \n",
    "    'kx', label = 'Data (%d points)' % (u_train.shape[0]), \n",
    "    markersize = 4, \n",
    "    clip_on = False,\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# 誤差の計算\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "# 温度分布の可視化\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 予測温度分布\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img3 = ax1.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img3, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Predicted Temperature Distribution')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Position [m]')\n",
    "\n",
    "# 残差の可視化\n",
    "ax2 = fig.add_subplot(212)\n",
    "h_img4 = ax2.imshow(Error.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider2 = make_axes_locatable(ax2)\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar2 = fig.colorbar(h_img4, cax=cax2)\n",
    "cbar2.ax.tick_params(labelsize=15)\n",
    "ax2.set_title('Absolute Error Distribution')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "ax2.set_ylabel('Position [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uをスケーリングさせた場合の正しい解のplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# スケーリング関数\n",
    "def scale_u(u, u_min, u_max):\n",
    "    return (u - u_min) / (u_max - u_min)\n",
    "\n",
    "def unscale_u(u_scaled, u_min, u_max):\n",
    "    return u_scaled * (u_max - u_min) + u_min\n",
    "\n",
    "# 定数\n",
    "K = 0.47\n",
    "rho = 1573\n",
    "cp = 967\n",
    "alpha = K / (rho * cp)\n",
    "h1 = 100\n",
    "h2 = 50\n",
    "\n",
    "# 位置と時間の定義\n",
    "x = np.linspace(0, 0.2, 100)[:, None]\n",
    "t = np.linspace(0, 3600, 3600)[:, None]\n",
    "dx = x[1] - x[0]\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "Nx = len(x)\n",
    "Nt = len(t)\n",
    "u = np.zeros((Nt, Nx))\n",
    "\n",
    "for n in range(0, Nt - 1):\n",
    "    if t[n] <= 600:\n",
    "        T_ext1 = T_ext2 = 0 + (50 - 0) * t[n] / 600\n",
    "    else:\n",
    "        T_ext1 = T_ext2 = 50\n",
    "    for i in range(1, Nx - 1):\n",
    "        u[n + 1, i] = u[n, i] + alpha * dt * (u[n, i - 1] - 2 * u[n, i] + u[n, i + 1]) / dx**2\n",
    "\n",
    "    u[n + 1, 0] = (4 * u[n + 1, 1] - u[n + 1, 2] + 2 * dx * h1 / K * T_ext1) / (3 + 2 * dx * h1 / K)\n",
    "    u[n + 1, -1] = (4 * u[n + 1, -2] - u[n + 1, -3] + 2 * dx * h2 / K * T_ext2) / (3 + 2 * dx * h2 / K)\n",
    "\n",
    "# スケーリング\n",
    "u_min, u_max = u.min(), u.max()\n",
    "u_scaled = scale_u(u, u_min, u_max)\n",
    "\n",
    "# プロット\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img1 = ax1.imshow(u_scaled.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img1, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Scaled Temperature Distribution', fontsize=15)\n",
    "ax1.set_xlabel('Time [s]', fontsize=12)\n",
    "ax1.set_ylabel('Position [m]', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xとtとuのスケーリング\n",
    "#ver2\n",
    "#希望ある。\n",
    "import sys\n",
    "sys.path.insert(0, './Utilities/')\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "K = 0.47\n",
    "rho = 1573\n",
    "cp = 967\n",
    "alpha = K / (rho * cp)\n",
    "\n",
    "h1 = 100\n",
    "h2 = 50\n",
    "\n",
    "lambda_u, lambda_f, lambda_BC0, lambda_BC1, lambda_BC2 = 1.0, 1.0, 1.0, 1.0, 1.0 \n",
    "\n",
    "N_u = 500\n",
    "N_f = 10000\n",
    "layers = [2, 50, 50, 50, 50, 50, 50, 50, 50, 1]\n",
    "\n",
    "x = np.linspace(0, 0.2, 100)[:, None]\n",
    "t = np.linspace(0, 3600, 3600)[:, None]\n",
    "dx = x[1] - x[0]\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "Nx = len(x)\n",
    "Nt = len(t)\n",
    "u = np.zeros((Nt, Nx))\n",
    "\n",
    "for n in range(0, Nt - 1):\n",
    "    if t[n] <= 600:\n",
    "        T_ext1 = T_ext2 = 0 + (50 - 0) * t[n] / 600\n",
    "    else:\n",
    "        T_ext1 = T_ext2 = 50\n",
    "    for i in range(1, Nx - 1):\n",
    "        u[n + 1, i] = u[n, i] + alpha * dt * (u[n, i - 1] - 2 * u[n, i] + u[n, i + 1]) / dx**2\n",
    "\n",
    "    u[n + 1, 0] = (4 * u[n + 1, 1] - u[n + 1, 2] + 2 * dx * h1 / K * T_ext1) / (3 + 2 * dx * h1 / K)\n",
    "    u[n + 1, -1] = (4 * u[n + 1, -2] - u[n + 1, -3] + 2 * dx * h2 / K * T_ext2) / (3 + 2 * dx * h2 / K)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img1 = ax1.imshow(u.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img1, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Exact Temperature Distribution', fontsize=15)\n",
    "ax1.set_xlabel('Time [s]', fontsize=12)\n",
    "ax1.set_ylabel('Position [m]', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = u.flatten()[:, None]\n",
    "\n",
    "# ドメインの境界\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "# print(lb, ub)\n",
    "# [0. 0.] [2.0e-01 3.6e+03]\n",
    "\n",
    "# 初期条件と境界条件のデータを準備\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = u[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = u[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = u[:, -1:]\n",
    "\n",
    "# xx1は初期条件。uu1はt=0の時の温度分布\n",
    "# print('xx1:', xx1.shape)→(100, 2)\n",
    "# print('uu1:', uu1.shape)→(100, 1)\n",
    "# xx2はx=0の境界条件。uu2はx=0の境界条件の温度分布\n",
    "# print('xx2:', xx2.shape)→(3600, 2)\n",
    "# print('xx2[:, 0:1]:', xx2[:, 0:1])\n",
    "# print('uu2:', uu2.shape)\n",
    "# print('uu2[:, 0:1]:', uu2[:, 0:1])\n",
    "# xx3はx=0.2の境界条件。uu3はx=0.2の境界条件の温度分布\n",
    "# print('xx3:', xx3.shape)→(3600, 2)\n",
    "# print('xx3[:, -1:]:', xx3[:, -1:])\n",
    "# print('uu3:', uu3.shape)\n",
    "# print('uu3[:, -1:]:', uu3[:, -1:])\n",
    "\n",
    "# 初期・境界条件のデータを結合\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "# print('X_u_train:', X_u_train.shape)→(7300, 2)。3600+3600+100=7300\n",
    "\n",
    "# ランダムサンプリング\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "# print('X_f_train:', X_f_train.shape)→(10000, 2)\n",
    "# print('X_f_train:', X_f_train)\n",
    "\n",
    "#ランダムサンプリングのデータと初期・境界条件のデータを結合\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "# print('X_f_train:', X_f_train.shape)→(17300, 2)\n",
    "# print('X_f_train.tail:', X_f_train[-1])\n",
    "\n",
    "# 初期・境界条件での温度分布\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "# print('u_train:', u_train.shape)→(500,1)\n",
    "\n",
    "# X_u_trainの行数からN_u個のランダムなインデックスを生成。\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "# 初期・境界条件のデータをN_u個に絞る\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]\n",
    "\n",
    "# まとめ\n",
    "# X_u_train: 初期・境界条件の位置・時間データ\n",
    "# u_train: 初期・境界条件の温度データ\n",
    "# X_f_train: ランダムサンプリングの位置・時間データ\n",
    "\n",
    "def scale_x(x):\n",
    "    return 2.0 * (x - lb[0]) / (ub[0] - lb[0]) - 1.0\n",
    "\n",
    "def scale_t(t):\n",
    "    return (t - lb[1]) / (ub[1] - lb[1])\n",
    "\n",
    "def scale_u(u):\n",
    "    return (u - u_min) / (u_max - u_min)\n",
    "\n",
    "def unscale_x(x):\n",
    "    return 0.5 * (x + 1.0) * (ub[0] - lb[0]) + lb[0]\n",
    "\n",
    "def unscale_t(t):\n",
    "    return t * (ub[1] - lb[1]) + lb[1]\n",
    "\n",
    "def unscale_u(u, u_min, u_max):\n",
    "    return u * (u_max - u_min) + u_min\n",
    "\n",
    "# 初期・境界条件・ランダムサンプリングのデータをスケーリング\n",
    "X_u_train_scaled = np.copy(X_u_train)\n",
    "X_u_train_scaled[:, 0] = scale_x(X_u_train[:, 0])\n",
    "X_u_train_scaled[:, 1] = scale_t(X_u_train[:, 1])\n",
    "\n",
    "X_f_train_scaled = np.copy(X_f_train)\n",
    "X_f_train_scaled[:, 0] = scale_x(X_f_train[:, 0])\n",
    "X_f_train_scaled[:, 1] = scale_t(X_f_train[:, 1])\n",
    "\n",
    "# print('X_u_train_scaled:', X_u_train_scaled[:10])\n",
    "# print('X_f_train_scaled:', X_f_train_scaled[:10])\n",
    "# print('X_u_train_scaleの位置の最小値:', X_u_train_scaled[:, 0].min()):-1\n",
    "# print('X_u_train_scaleの位置の最大値:', X_u_train_scaled[:, 0].max()):1\n",
    "# print('X_u_train_scaleの時間の最小値:', X_u_train_scaled[:, 1].min()):0\n",
    "# print('X_u_train_scaleの時間の最大値:', X_u_train_scaled[:, 1].max()):1\n",
    "# print('X_f_train_scaleの位置の最小値:', X_f_train_scaled[:, 0].min()):-1\n",
    "# print('X_f_train_scaleの位置の最大値:', X_f_train_scaled[:, 0].max()):1\n",
    "# print('X_f_train_scaleの時間の最小値:', X_f_train_scaled[:, 1].min()):0\n",
    "# print('X_f_train_scaleの時間の最大値:', X_f_train_scaled[:, 1].max()):1\n",
    "\n",
    "# 温度データのスケーリング\n",
    "# 設定変える時はここも変える\n",
    "u_min, u_max = 0, 50\n",
    "u_train_scaled = scale_u(u_train)\n",
    "# print('u_min', u_min):0\n",
    "# print('u_max', u_max):45.880\n",
    "# print('u_train_scaled:', u_train_scaled[:10])\n",
    "# print('u_train_scaledの最小値:', u_train_scaled.min()):0\n",
    "# print('u_train_scaledの最大値:', u_train_scaled.max()):1.0\n",
    "\n",
    "T0 = u_train[X_u_train[:,1] == 0].mean().item()\n",
    "T0_scaled = scale_u(T0)\n",
    "# print('T0:', T0):0.0\n",
    "\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = torch.nn.ELU\n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(('layer_%d' % i, torch.nn.Linear(layers[i], layers[i + 1])))\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "        layer_list.append(('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1])))\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, rho, cp, alpha, k, h1, h2, T0):\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        self.x_u = torch.tensor(X_u[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_u = torch.tensor(X_u[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        self.layers = layers\n",
    "        self.k = k\n",
    "        self.rho = rho\n",
    "        self.alpha = alpha\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.T0 = T0\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters(), lr=1e-4)\n",
    "        self.lambda_f = torch.tensor(lambda_f, requires_grad=True, device=device)\n",
    "        self.lambda_BC0 = torch.tensor(lambda_BC0, requires_grad=True, device=device)\n",
    "        self.lambda_BC1 = torch.tensor(lambda_BC1, requires_grad=True, device=device)\n",
    "        self.lambda_BC2 = torch.tensor(lambda_BC2, requires_grad=True, device=device)\n",
    "\n",
    "    def net_t_inf(self, t):\n",
    "        t_unscaled = unscale_t(t)\n",
    "        t_inf_unscaled = torch.where(t_unscaled <= 600, 50 * t_unscaled / 600, torch.tensor(50.0).to(device))\n",
    "        t_inf = scale_t(t_inf_unscaled)\n",
    "        return t_inf\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        u = self.dnn(torch.cat([x, t], dim=1))\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        f = self.alpha * u_xx - u_t\n",
    "        return f\n",
    "\n",
    "    def net_BC0(self, x):\n",
    "        t = torch.zeros_like(x)\n",
    "        u = self.net_u(x, t)\n",
    "        BC0 = self.T0 - u\n",
    "        return BC0\n",
    "\n",
    "    def net_BC1(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC1 = - (t_inf - u) + (self.k / self.h1) * u_x\n",
    "        return BC1\n",
    "\n",
    "    def net_BC2(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC2 = t_inf - u - (self.k / self.h2) * u_x\n",
    "        return BC2\n",
    "\n",
    "    def loss_func(self):\n",
    "        f_pred = self.net_f(self.x_f, self.t_f)\n",
    "        x_BC0 = self.x_f[self.t_f == 0]\n",
    "        BC0_pred = self.net_BC0(x_BC0)\n",
    "        x_BC1 = torch.full((self.t_f.shape[0], 1), 1.0, requires_grad=True).to(device)\n",
    "        t_BC1 = self.t_f\n",
    "        BC1_pred = self.net_BC1(x_BC1, t_BC1)\n",
    "        x_BC2 = torch.full((self.t_f.shape[0], 1), -1.0, requires_grad=True).to(device)\n",
    "        t_BC2 = self.t_f\n",
    "        BC2_pred = self.net_BC2(x_BC2, t_BC2)\n",
    "        loss_f = torch.mean(f_pred**2)\n",
    "        loss_BC0 = torch.mean(BC0_pred**2)\n",
    "        loss_BC1 = torch.mean(BC1_pred**2)\n",
    "        loss_BC2 = torch.mean(BC2_pred**2)\n",
    "        total_loss = self.lambda_f * loss_f + self.lambda_BC0 * loss_BC0 + self.lambda_BC1 * loss_BC1 + self.lambda_BC2 * loss_BC2\n",
    "        return total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2\n",
    "\n",
    "    def train(self, nIter):\n",
    "        for epoch in range(nIter):\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2 = self.loss_func()\n",
    "            total_loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            with torch.no_grad():\n",
    "                self.lambda_f *= torch.exp(0.1 * loss_f.detach() / total_loss.detach())\n",
    "                self.lambda_BC0 *= torch.exp(0.1 * loss_BC0.detach() / total_loss.detach())\n",
    "                self.lambda_BC1 *= torch.exp(0.1 * loss_BC1.detach() / total_loss.detach())\n",
    "                self.lambda_BC2 *= torch.exp(0.1 * loss_BC2.detach() / total_loss.detach())\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}: Total Loss: {total_loss.item():.4e}, Loss f: {loss_f.item():.4e}, Loss BC0: {loss_BC0.item():.4e}, Loss BC1: {loss_BC1.item():.4e}, Loss BC2: {loss_BC2.item():.4e}')\n",
    "                print(f'lambda_f: {self.lambda_f.item()}, lambda_BC0: {self.lambda_BC0.item()}, lambda_BC1: {self.lambda_BC1.item()}, lambda_BC2: {self.lambda_BC2.item()}')\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        x_star = torch.tensor(X_star[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t_star = torch.tensor(X_star[:, 1:2], requires_grad=True).float().to(device)\n",
    "        x_star_scaled = scale_x(x_star)\n",
    "        t_star_scaled = scale_t(t_star)\n",
    "        u_pred_scaled = self.net_u(x_star_scaled, t_star_scaled)\n",
    "        u_pred = unscale_u(u_pred_scaled, 0, 50)\n",
    "        return u_pred.detach().cpu().numpy()\n",
    "\n",
    "# モデルのインスタンス化\n",
    "# model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0)\n",
    "model = PhysicsInformedNN(X_u_train_scaled, u_train_scaled, X_f_train_scaled, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0_scaled)\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.train(15000)\n",
    "\n",
    "# 予測\n",
    "u_pred = model.predict(X_star)\n",
    "\n",
    "# 誤差の計算\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "print('Error u: %e' % (error_u))                     \n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h_img2 = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "              extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar = fig.colorbar(h_img2, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "ax.plot(\n",
    "    X_u_train[:,1], \n",
    "    X_u_train[:,0], \n",
    "    'kx', label = 'Data (%d points)' % (u_train.shape[0]), \n",
    "    markersize = 4, \n",
    "    clip_on = False,\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# 誤差の計算\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "# 温度分布の可視化\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 予測温度分布\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img3 = ax1.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img3, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Predicted Temperature Distribution')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Position [m]')\n",
    "\n",
    "# 残差の可視化\n",
    "ax2 = fig.add_subplot(212)\n",
    "h_img4 = ax2.imshow(Error.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider2 = make_axes_locatable(ax2)\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar2 = fig.colorbar(h_img4, cax=cax2)\n",
    "cbar2.ax.tick_params(labelsize=15)\n",
    "ax2.set_title('Absolute Error Distribution')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "ax2.set_ylabel('Position [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xとtとuのスケーリング\n",
    "#ver2\n",
    "#希望ある。\n",
    "import sys\n",
    "sys.path.insert(0, './Utilities/')\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "K = 0.47\n",
    "rho = 1573\n",
    "cp = 967\n",
    "alpha = K / (rho * cp)\n",
    "\n",
    "h1 = 100\n",
    "h2 = 50\n",
    "\n",
    "lambda_u, lambda_f, lambda_BC0, lambda_BC1, lambda_BC2 = 1.0, 1.0, 1.0, 1.0, 1.0 \n",
    "\n",
    "N_u = 500\n",
    "N_f = 10000\n",
    "layers = [2, 50, 50, 50, 50, 50, 50, 50, 50, 1]\n",
    "\n",
    "x = np.linspace(0, 0.2, 100)[:, None]\n",
    "t = np.linspace(0, 3600, 3600)[:, None]\n",
    "dx = x[1] - x[0]\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "Nx = len(x)\n",
    "Nt = len(t)\n",
    "u = np.zeros((Nt, Nx))\n",
    "\n",
    "for n in range(0, Nt - 1):\n",
    "    if t[n] <= 600:\n",
    "        T_ext1 = T_ext2 = 0 + (50 - 0) * t[n] / 600\n",
    "    else:\n",
    "        T_ext1 = T_ext2 = 50\n",
    "    for i in range(1, Nx - 1):\n",
    "        u[n + 1, i] = u[n, i] + alpha * dt * (u[n, i - 1] - 2 * u[n, i] + u[n, i + 1]) / dx**2\n",
    "\n",
    "    u[n + 1, 0] = (4 * u[n + 1, 1] - u[n + 1, 2] + 2 * dx * h1 / K * T_ext1) / (3 + 2 * dx * h1 / K)\n",
    "    u[n + 1, -1] = (4 * u[n + 1, -2] - u[n + 1, -3] + 2 * dx * h2 / K * T_ext2) / (3 + 2 * dx * h2 / K)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img1 = ax1.imshow(u.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img1, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Exact Temperature Distribution', fontsize=15)\n",
    "ax1.set_xlabel('Time [s]', fontsize=12)\n",
    "ax1.set_ylabel('Position [m]', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = u.flatten()[:, None]\n",
    "\n",
    "# ドメインの境界\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "# print(lb, ub)\n",
    "# [0. 0.] [2.0e-01 3.6e+03]\n",
    "\n",
    "# 初期条件と境界条件のデータを準備\n",
    "xx1 = np.hstack((X[0:1, :].T, T[0:1, :].T))\n",
    "uu1 = u[0:1, :].T\n",
    "xx2 = np.hstack((X[:, 0:1], T[:, 0:1]))\n",
    "uu2 = u[:, 0:1]\n",
    "xx3 = np.hstack((X[:, -1:], T[:, -1:]))\n",
    "uu3 = u[:, -1:]\n",
    "\n",
    "# xx1は初期条件。uu1はt=0の時の温度分布\n",
    "# print('xx1:', xx1.shape)→(100, 2)\n",
    "# print('uu1:', uu1.shape)→(100, 1)\n",
    "# xx2はx=0の境界条件。uu2はx=0の境界条件の温度分布\n",
    "# print('xx2:', xx2.shape)→(3600, 2)\n",
    "# print('xx2[:, 0:1]:', xx2[:, 0:1])\n",
    "# print('uu2:', uu2.shape)\n",
    "# print('uu2[:, 0:1]:', uu2[:, 0:1])\n",
    "# xx3はx=0.2の境界条件。uu3はx=0.2の境界条件の温度分布\n",
    "# print('xx3:', xx3.shape)→(3600, 2)\n",
    "# print('xx3[:, -1:]:', xx3[:, -1:])\n",
    "# print('uu3:', uu3.shape)\n",
    "# print('uu3[:, -1:]:', uu3[:, -1:])\n",
    "\n",
    "# 初期・境界条件のデータを結合\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "# print('X_u_train:', X_u_train.shape)→(7300, 2)。3600+3600+100=7300\n",
    "\n",
    "# ランダムサンプリング\n",
    "X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "# print('X_f_train:', X_f_train.shape)→(10000, 2)\n",
    "# print('X_f_train:', X_f_train)\n",
    "\n",
    "#ランダムサンプリングのデータと初期・境界条件のデータを結合\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "# print('X_f_train:', X_f_train.shape)→(17300, 2)\n",
    "# print('X_f_train.tail:', X_f_train[-1])\n",
    "\n",
    "# 初期・境界条件での温度分布\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "# print('u_train:', u_train.shape)→(500,1)\n",
    "\n",
    "# X_u_trainの行数からN_u個のランダムなインデックスを生成。\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "# 初期・境界条件のデータをN_u個に絞る\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx, :]\n",
    "\n",
    "# まとめ\n",
    "# X_u_train: 初期・境界条件の位置・時間データ\n",
    "# u_train: 初期・境界条件の温度データ\n",
    "# X_f_train: ランダムサンプリングの位置・時間データ\n",
    "\n",
    "def scale_x(x):\n",
    "    return 2.0 * (x - lb[0]) / (ub[0] - lb[0]) - 1.0\n",
    "\n",
    "def scale_t(t):\n",
    "    return (t - lb[1]) / (ub[1] - lb[1])\n",
    "\n",
    "def scale_u(u):\n",
    "    return (u - u_min) / (u_max - u_min)\n",
    "\n",
    "def unscale_x(x):\n",
    "    return 0.5 * (x + 1.0) * (ub[0] - lb[0]) + lb[0]\n",
    "\n",
    "def unscale_t(t):\n",
    "    return t * (ub[1] - lb[1]) + lb[1]\n",
    "\n",
    "def unscale_u(u, u_min, u_max):\n",
    "    return u * (u_max - u_min) + u_min\n",
    "\n",
    "# 初期・境界条件・ランダムサンプリングのデータをスケーリング\n",
    "X_u_train_scaled = np.copy(X_u_train)\n",
    "X_u_train_scaled[:, 0] = scale_x(X_u_train[:, 0])\n",
    "X_u_train_scaled[:, 1] = scale_t(X_u_train[:, 1])\n",
    "\n",
    "X_f_train_scaled = np.copy(X_f_train)\n",
    "X_f_train_scaled[:, 0] = scale_x(X_f_train[:, 0])\n",
    "X_f_train_scaled[:, 1] = scale_t(X_f_train[:, 1])\n",
    "\n",
    "# print('X_u_train_scaled:', X_u_train_scaled[:10])\n",
    "# print('X_f_train_scaled:', X_f_train_scaled[:10])\n",
    "# print('X_u_train_scaleの位置の最小値:', X_u_train_scaled[:, 0].min()):-1\n",
    "# print('X_u_train_scaleの位置の最大値:', X_u_train_scaled[:, 0].max()):1\n",
    "# print('X_u_train_scaleの時間の最小値:', X_u_train_scaled[:, 1].min()):0\n",
    "# print('X_u_train_scaleの時間の最大値:', X_u_train_scaled[:, 1].max()):1\n",
    "# print('X_f_train_scaleの位置の最小値:', X_f_train_scaled[:, 0].min()):-1\n",
    "# print('X_f_train_scaleの位置の最大値:', X_f_train_scaled[:, 0].max()):1\n",
    "# print('X_f_train_scaleの時間の最小値:', X_f_train_scaled[:, 1].min()):0\n",
    "# print('X_f_train_scaleの時間の最大値:', X_f_train_scaled[:, 1].max()):1\n",
    "\n",
    "# 温度データのスケーリング\n",
    "# 設定変える時はここも変える\n",
    "u_min, u_max = 0, 50\n",
    "u_train_scaled = scale_u(u_train)\n",
    "# print('u_min', u_min):0\n",
    "# print('u_max', u_max):45.880\n",
    "# print('u_train_scaled:', u_train_scaled[:10])\n",
    "# print('u_train_scaledの最小値:', u_train_scaled.min()):0\n",
    "# print('u_train_scaledの最大値:', u_train_scaled.max()):1.0\n",
    "\n",
    "T0 = u_train[X_u_train[:,1] == 0].mean().item()\n",
    "T0_scaled = scale_u(T0)\n",
    "# print('T0:', T0):0.0\n",
    "\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = torch.nn.ELU\n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(('layer_%d' % i, torch.nn.Linear(layers[i], layers[i + 1])))\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "        layer_list.append(('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1])))\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, rho, cp, alpha, k, h1, h2, T0):\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        self.x_u = torch.tensor(X_u[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_u = torch.tensor(X_u[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        self.layers = layers\n",
    "        self.k = k\n",
    "        self.rho = rho\n",
    "        self.alpha = alpha\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.T0 = T0\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters(), lr=1e-4)\n",
    "        self.lambda_f = torch.tensor(lambda_f, requires_grad=True, device=device)\n",
    "        self.lambda_BC0 = torch.tensor(lambda_BC0, requires_grad=True, device=device)\n",
    "        self.lambda_BC1 = torch.tensor(lambda_BC1, requires_grad=True, device=device)\n",
    "        self.lambda_BC2 = torch.tensor(lambda_BC2, requires_grad=True, device=device)\n",
    "\n",
    "    def net_t_inf(self, t):\n",
    "        t_unscaled = unscale_t(t)\n",
    "        t_inf_unscaled = torch.where(t_unscaled <= 600, 50 * t_unscaled / 600, torch.tensor(50.0).to(device))\n",
    "        t_inf = scale_t(t_inf_unscaled)\n",
    "        return t_inf\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        u = self.dnn(torch.cat([x, t], dim=1))\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        f = self.alpha * u_xx - u_t\n",
    "        return f\n",
    "\n",
    "    def net_BC0(self, x):\n",
    "        t = torch.zeros_like(x)\n",
    "        u = self.net_u(x, t)\n",
    "        BC0 = self.T0 - u\n",
    "        return BC0\n",
    "\n",
    "    def net_BC1(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC1 = - (t_inf - u) + (self.k / self.h1) * u_x\n",
    "        return BC1\n",
    "\n",
    "    def net_BC2(self, x, t):\n",
    "        t_inf = self.net_t_inf(t)\n",
    "        u = self.net_u(x, t)\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        BC2 = t_inf - u - (self.k / self.h2) * u_x\n",
    "        return BC2\n",
    "\n",
    "    def loss_func(self):\n",
    "        f_pred = self.net_f(self.x_f, self.t_f)\n",
    "        x_BC0 = self.x_f[self.t_f == 0]\n",
    "        BC0_pred = self.net_BC0(x_BC0)\n",
    "        x_BC1 = torch.full((self.t_f.shape[0], 1), 1.0, requires_grad=True).to(device)\n",
    "        t_BC1 = self.t_f\n",
    "        BC1_pred = self.net_BC1(x_BC1, t_BC1)\n",
    "        x_BC2 = torch.full((self.t_f.shape[0], 1), -1.0, requires_grad=True).to(device)\n",
    "        t_BC2 = self.t_f\n",
    "        BC2_pred = self.net_BC2(x_BC2, t_BC2)\n",
    "        loss_f = torch.mean(f_pred**2)\n",
    "        loss_BC0 = torch.mean(BC0_pred**2)\n",
    "        loss_BC1 = torch.mean(BC1_pred**2)\n",
    "        loss_BC2 = torch.mean(BC2_pred**2)\n",
    "        total_loss = self.lambda_f * loss_f + self.lambda_BC0 * loss_BC0 + self.lambda_BC1 * loss_BC1 + self.lambda_BC2 * loss_BC2\n",
    "        return total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2\n",
    "\n",
    "    def train(self, nIter):\n",
    "        for epoch in range(nIter):\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            total_loss, loss_f, loss_BC0, loss_BC1, loss_BC2 = self.loss_func()\n",
    "            total_loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            with torch.no_grad():\n",
    "                self.lambda_f *= torch.exp(0.1 * loss_f.detach() / total_loss.detach())\n",
    "                self.lambda_BC0 *= torch.exp(0.1 * loss_BC0.detach() / total_loss.detach())\n",
    "                self.lambda_BC1 *= torch.exp(0.1 * loss_BC1.detach() / total_loss.detach())\n",
    "                self.lambda_BC2 *= torch.exp(0.1 * loss_BC2.detach() / total_loss.detach())\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}: Total Loss: {total_loss.item():.4e}, Loss f: {loss_f.item():.4e}, Loss BC0: {loss_BC0.item():.4e}, Loss BC1: {loss_BC1.item():.4e}, Loss BC2: {loss_BC2.item():.4e}')\n",
    "                print(f'lambda_f: {self.lambda_f.item()}, lambda_BC0: {self.lambda_BC0.item()}, lambda_BC1: {self.lambda_BC1.item()}, lambda_BC2: {self.lambda_BC2.item()}')\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        x_star = torch.tensor(X_star[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t_star = torch.tensor(X_star[:, 1:2], requires_grad=True).float().to(device)\n",
    "        x_star_scaled = scale_x(x_star)\n",
    "        t_star_scaled = scale_t(t_star)\n",
    "        u_pred_scaled = self.net_u(x_star_scaled, t_star_scaled)\n",
    "        u_pred = unscale_u(u_pred_scaled, 0, 50)\n",
    "        return u_pred.detach().cpu().numpy()\n",
    "\n",
    "# モデルのインスタンス化\n",
    "# model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0)\n",
    "model = PhysicsInformedNN(X_u_train_scaled, u_train_scaled, X_f_train_scaled, layers, lb, ub, alpha, rho, cp, K, h1, h2, T0_scaled)\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.train(1000)\n",
    "\n",
    "# 予測\n",
    "u_pred = model.predict(X_star)\n",
    "\n",
    "# 誤差の計算\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "print('Error u: %e' % (error_u))                     \n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h_img2 = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "              extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar = fig.colorbar(h_img2, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "ax.plot(\n",
    "    X_u_train[:,1], \n",
    "    X_u_train[:,0], \n",
    "    'kx', label = 'Data (%d points)' % (u_train.shape[0]), \n",
    "    markersize = 4, \n",
    "    clip_on = False,\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# 誤差の計算\n",
    "Error = np.abs(u - U_pred)\n",
    "\n",
    "# 温度分布の可視化\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 予測温度分布\n",
    "ax1 = fig.add_subplot(211)\n",
    "h_img3 = ax1.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar1 = fig.colorbar(h_img3, cax=cax1)\n",
    "cbar1.ax.tick_params(labelsize=15)\n",
    "ax1.set_title('Predicted Temperature Distribution')\n",
    "ax1.set_xlabel('Time [s]')\n",
    "ax1.set_ylabel('Position [m]')\n",
    "\n",
    "# 残差の可視化\n",
    "ax2 = fig.add_subplot(212)\n",
    "h_img4 = ax2.imshow(Error.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "divider2 = make_axes_locatable(ax2)\n",
    "cax2 = divider2.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar2 = fig.colorbar(h_img4, cax=cax2)\n",
    "cbar2.ax.tick_params(labelsize=15)\n",
    "ax2.set_title('Absolute Error Distribution')\n",
    "ax2.set_xlabel('Time [s]')\n",
    "ax2.set_ylabel('Position [m]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
